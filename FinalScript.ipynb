{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cb03f0",
   "metadata": {},
   "source": [
    "Autonomous Robotics\n",
    "Ex0 - GNSS Raw Mesurments\n",
    "FINAL SOLUTION\n",
    "\n",
    "Submitter: \n",
    "Shlomit Ashkenazi\n",
    "\n",
    "Sources:\n",
    "https://www.johnsonmitchelld.com/2021/03/14/least-squares-gps.html \n",
    "https://github.com/johnsonmitchelld/gnss-analysis/tree/main/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e416b0",
   "metadata": {},
   "source": [
    "# the final solution (Part c on readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2a086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving gnss/data/daily/2021/brdc/brdc0090.21n.gz from gdc.cddis.eosdis.nasa.gov\n"
     ]
    }
   ],
   "source": [
    "from ftplib import FTP_TLS, FTP\n",
    "import ftplib\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import georinex\n",
    "import xarray\n",
    "import unlzw3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Took it from  https://github.com/johnsonmitchelld/gnss-analysis/tree/main/notebooks\n",
    "class EphemerisManager():\n",
    "    def __init__(self, data_directory=os.path.join(os.getcwd(), 'data', 'ephemeris')):\n",
    "        self.data_directory = data_directory\n",
    "        nasa_dir = os.path.join(data_directory, 'nasa')\n",
    "        igs_dir = os.path.join(data_directory, 'igs')\n",
    "        os.makedirs(nasa_dir, exist_ok=True)\n",
    "        os.makedirs(igs_dir, exist_ok=True)\n",
    "        self.data = None\n",
    "        self.leapseconds = None\n",
    "\n",
    "    def get_ephemeris(self, timestamp, satellites):\n",
    "        systems = EphemerisManager.get_constellations(satellites)\n",
    "        if not isinstance(self.data, pd.DataFrame):\n",
    "            self.load_data(timestamp, systems)\n",
    "        data = self.data\n",
    "        if satellites:\n",
    "            data = data.loc[data['sv'].isin(satellites)]\n",
    "        data = data.loc[data['time'] < timestamp]\n",
    "        data = data.sort_values('time').groupby('sv').last().drop('index', axis=1)\n",
    "        data['Leap Seconds'] = self.leapseconds\n",
    "        return data\n",
    "\n",
    "    def get_leapseconds(self, timestamp):\n",
    "        return self.leapseconds\n",
    "\n",
    "    def load_data(self, timestamp, constellations=None):\n",
    "        filepaths = EphemerisManager.get_filepaths(timestamp)\n",
    "        data_list = []\n",
    "        timestamp_age = datetime.now(timezone.utc) - timestamp\n",
    "        if constellations == None:\n",
    "            for fileinfo in filepaths.values():\n",
    "                data = self.get_ephemeris_dataframe(fileinfo)\n",
    "                data_list.append(data)\n",
    "        else:\n",
    "            legacy_systems = set(['G', 'R'])\n",
    "            legacy_systems_only = len(constellations - legacy_systems) == 0\n",
    "            if timestamp_age.days > 0:\n",
    "                if legacy_systems_only:\n",
    "                    data_list.append(self.get_ephemeris_dataframe(\n",
    "                        filepaths['nasa_daily_gps']))\n",
    "                    if 'R' in constellations:\n",
    "                        data_list.append(self.get_ephemeris_dataframe(\n",
    "                            filepaths['nasa_daily_glonass']))\n",
    "                else:\n",
    "                    data_list.append(self.get_ephemeris_dataframe(\n",
    "                        filepaths['nasa_daily_combined']))\n",
    "            else:\n",
    "                data_list.append(self.get_ephemeris_dataframe(\n",
    "                    filepaths['nasa_daily_gps']))\n",
    "                if not legacy_systems_only:\n",
    "                    data_list.append(self.get_ephemeris_dataframe(\n",
    "                        filepaths['bkg_daily_combined']))\n",
    "\n",
    "        data = pd.DataFrame()\n",
    "        data = pd.concat(data_list, ignore_index=True) ## DataFrame.append is deprectaed...\n",
    "        data.reset_index(inplace=True)\n",
    "        data.sort_values('time', inplace=True, ignore_index=True)\n",
    "        self.data = data\n",
    "\n",
    "    def get_ephemeris_dataframe(self, fileinfo, constellations=None):\n",
    "        filepath = fileinfo['filepath']\n",
    "        url = fileinfo['url']\n",
    "        directory = os.path.split(filepath)[0]\n",
    "        filename = os.path.split(filepath)[1]\n",
    "        if url == 'igs.bkg.bund.de':\n",
    "            dest_filepath = os.path.join(self.data_directory, 'igs', filename)\n",
    "        else:\n",
    "            dest_filepath = os.path.join(self.data_directory, 'nasa', filename)\n",
    "        decompressed_filename = os.path.splitext(dest_filepath)[0]\n",
    "        if not os.path.isfile(decompressed_filename):\n",
    "            if url == 'gdc.cddis.eosdis.nasa.gov':\n",
    "                secure = True\n",
    "            else:\n",
    "                secure = False\n",
    "            try:\n",
    "                self.retrieve_file(url, directory, filename,\n",
    "                                   dest_filepath, secure)\n",
    "                self.decompress_file(dest_filepath)\n",
    "            except ftplib.error_perm as err:\n",
    "                print('ftp error')\n",
    "                return pd.DataFrame()\n",
    "        if not self.leapseconds:\n",
    "            self.leapseconds = EphemerisManager.load_leapseconds(\n",
    "                decompressed_filename)\n",
    "        if constellations:\n",
    "            data = georinex.load(decompressed_filename,\n",
    "                                 use=constellations).to_dataframe()\n",
    "        else:\n",
    "            data = georinex.load(decompressed_filename).to_dataframe()\n",
    "        data.dropna(how='all', inplace=True)\n",
    "        data.reset_index(inplace=True)\n",
    "        data['source'] = decompressed_filename\n",
    "        WEEKSEC = 604800\n",
    "        data['t_oc'] = pd.to_numeric(data['time'] - datetime(1980, 1, 6, 0, 0, 0))\n",
    "        data['t_oc']  = 1e-9 * data['t_oc'] - WEEKSEC * np.floor(1e-9 * data['t_oc'] / WEEKSEC)\n",
    "        data['time'] = data['time'].dt.tz_localize('UTC')\n",
    "        data.rename(columns={'M0': 'M_0', 'Eccentricity': 'e', 'Toe': 't_oe', 'DeltaN': 'deltaN', 'Cuc': 'C_uc', 'Cus': 'C_us',\n",
    "                             'Cic': 'C_ic', 'Crc': 'C_rc', 'Cis': 'C_is', 'Crs': 'C_rs', 'Io': 'i_0', 'Omega0': 'Omega_0'}, inplace=True)\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def get_filetype(timestamp):\n",
    "        # IGS switched from .Z to .gz compression format on December 1st, 2020\n",
    "        if timestamp >= datetime(2020, 12, 1, 0, 0, 0, tzinfo=timezone.utc):\n",
    "            extension = '.gz'\n",
    "        else:\n",
    "            extension = '.Z'\n",
    "        return extension\n",
    "\n",
    "    @staticmethod\n",
    "    def load_leapseconds(filename):\n",
    "        with open(filename) as f:\n",
    "            for line in f:\n",
    "                if 'LEAP SECONDS' in line:\n",
    "                    return int(line.split()[0])\n",
    "                if 'END OF HEADER' in line:\n",
    "                    return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_constellations(satellites):\n",
    "        if type(satellites) is list:\n",
    "            systems = set()\n",
    "            for sat in satellites:\n",
    "                systems.add(sat[0])\n",
    "            return systems\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_toc(timestamp):\n",
    "        pass\n",
    "\n",
    "    def retrieve_file(self, url, directory, filename, dest_filepath, secure=False):\n",
    "        print('Retrieving ' + directory + '/' + filename + ' from ' + url)\n",
    "        ftp = self.connect(url, secure)\n",
    "        src_filepath = directory + '/' + filename\n",
    "        try:\n",
    "            with open(dest_filepath, 'wb') as handle:\n",
    "                ftp.retrbinary(\n",
    "                    'RETR ' + src_filepath, handle.write)\n",
    "        except ftplib.error_perm as err:\n",
    "            print('Failed to retrieve ' + src_filepath + ' from ' + url)\n",
    "            print(err)\n",
    "            os.remove(dest_filepath)\n",
    "            raise ftplib.error_perm\n",
    "\n",
    "    def decompress_file(self, filepath):\n",
    "        extension = os.path.splitext(filepath)[1]\n",
    "        decompressed_path = os.path.splitext(filepath)[0]\n",
    "        if extension == '.gz':\n",
    "            with gzip.open(filepath, 'rb') as f_in:\n",
    "                with open(decompressed_path, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "        elif extension == '.Z':\n",
    "            with open(filepath, 'rb') as f_in:\n",
    "                with open(decompressed_path, 'wb') as f_out:\n",
    "                    f_out.write(unlzw3.unlzw(f_in.read()))\n",
    "        os.remove(filepath)\n",
    "\n",
    "    def connect(self, url, secure):\n",
    "        if secure:\n",
    "            ftp = FTP_TLS(url)\n",
    "            ftp.login()\n",
    "            ftp.prot_p()\n",
    "        else:\n",
    "            ftp = FTP(url)\n",
    "            ftp.login()\n",
    "        return ftp\n",
    "\n",
    "    def listdir(self, url, directory, secure):\n",
    "        ftp = self.connect(url, secure)\n",
    "        dirlist = ftp.nlst(directory)\n",
    "        dirlist = [x for x in dirlist]\n",
    "        print(dirlist)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_filepaths(timestamp):\n",
    "        timetuple = timestamp.timetuple()\n",
    "        extension = EphemerisManager.get_filetype(timestamp)\n",
    "        filepaths = {}\n",
    "\n",
    "        directory = 'gnss/data/daily/' + str(timetuple.tm_year) + '/brdc/'\n",
    "        filename = 'BRDC00IGS_R_' + \\\n",
    "            str(timetuple.tm_year) + \\\n",
    "            str(timetuple.tm_yday).zfill(3) + '0000_01D_MN.rnx.gz'\n",
    "        filepaths['nasa_daily_combined'] = {\n",
    "            'filepath': directory + filename, 'url': 'gdc.cddis.eosdis.nasa.gov'}\n",
    "\n",
    "        filename = 'brdc' + str(timetuple.tm_yday).zfill(3) + \\\n",
    "            '0.' + str(timetuple.tm_year)[-2:] + 'n' + extension\n",
    "        filepaths['nasa_daily_gps'] = {\n",
    "            'filepath': directory + filename, 'url': 'gdc.cddis.eosdis.nasa.gov'}\n",
    "\n",
    "        filename = 'brdc' + str(timetuple.tm_yday).zfill(3) + \\\n",
    "            '0.' + str(timetuple.tm_year)[-2:] + 'g' + extension\n",
    "        filepaths['nasa_daily_glonass'] = {\n",
    "            'filepath': directory + filename, 'url': 'gdc.cddis.eosdis.nasa.gov'}\n",
    "\n",
    "        directory = '/IGS/BRDC/' + \\\n",
    "            str(timetuple.tm_year) + '/' + \\\n",
    "            str(timetuple.tm_yday).zfill(3) + '/'\n",
    "        filename = 'BRDC00WRD_S_' + \\\n",
    "            str(timetuple.tm_year) + \\\n",
    "            str(timetuple.tm_yday).zfill(3) + '0000_01D_MN.rnx.gz'\n",
    "        filepaths['bkg_daily_combined'] = {\n",
    "            'filepath': directory + filename, 'url': 'igs.bkg.bund.de'}\n",
    "\n",
    "        return filepaths\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    repo = EphemerisManager()\n",
    "    target_time = datetime(2021, 1, 9, 12, 0, 0, tzinfo=timezone.utc)\n",
    "    data = repo.get_ephemeris(target_time, ['G01', 'G03'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "523a26b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnss_log_2024_04_13_19_53_33.kml gnss_log_2024_04_13_19_53_33.csv\n",
      "gnss_log_2024_04_13_19_52_00.kml gnss_log_2024_04_13_19_52_00.csv\n",
      "gnss_log_2024_04_13_19_51_17.kml gnss_log_2024_04_13_19_51_17.csv\n",
      "End of Script\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import navpy\n",
    "import simplekml\n",
    "import csv\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "LIGHTSPEED = 2.99792458e8\n",
    "\n",
    "#took help from https://www.johnsonmitchelld.com/2021/03/14/least-squares-gps.html\n",
    "\n",
    "\n",
    "#parse tool (2)\n",
    "def parse_gnss_log(filepath):\n",
    "    with open(filepath) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if row[0][0] == '#':\n",
    "                if 'Fix' in row[0]:\n",
    "                    android_fixes = [row[1:]]\n",
    "                elif 'Raw' in row[0]:\n",
    "                    measurements = [row[1:]]\n",
    "            else:\n",
    "                if row[0] == 'Fix':\n",
    "                    android_fixes.append(row[1:])\n",
    "                elif row[0] == 'Raw':\n",
    "                    measurements.append(row[1:])\n",
    "\n",
    "    android_fixes = pd.DataFrame(android_fixes[1:], columns=android_fixes[0])\n",
    "    measurements = pd.DataFrame(measurements[1:], columns=measurements[0])\n",
    "    \n",
    "    # Format satellite IDs\n",
    "    measurements.loc[measurements['Svid'].str.len() == 1, 'Svid'] = '0' + measurements['Svid']\n",
    "    measurements.loc[measurements['ConstellationType'] == '1', 'Constellation'] = 'G'\n",
    "    measurements.loc[measurements['ConstellationType'] == '3', 'Constellation'] = 'R'\n",
    "    measurements['SvName'] = measurements['Constellation'] + measurements['Svid']\n",
    "    \n",
    "    # Remove all non-GPS measurements\n",
    "    measurements = measurements.loc[measurements['Constellation'] == 'G']\n",
    "    \n",
    "    # Convert columns to numeric representation\n",
    "    measurements['Cn0DbHz'] = pd.to_numeric(measurements['Cn0DbHz'])\n",
    "    measurements['TimeNanos'] = pd.to_numeric(measurements['TimeNanos'])\n",
    "    measurements['FullBiasNanos'] = pd.to_numeric(measurements['FullBiasNanos'])\n",
    "    measurements['ReceivedSvTimeNanos'] = pd.to_numeric(measurements['ReceivedSvTimeNanos'])\n",
    "    measurements['PseudorangeRateMetersPerSecond'] = pd.to_numeric(measurements['PseudorangeRateMetersPerSecond'])\n",
    "    measurements['ReceivedSvTimeUncertaintyNanos'] = pd.to_numeric(measurements['ReceivedSvTimeUncertaintyNanos'])\n",
    "    \n",
    "    if 'BiasNanos' in measurements.columns:\n",
    "        measurements['BiasNanos'] = pd.to_numeric(measurements['BiasNanos'])\n",
    "    else:\n",
    "        measurements['BiasNanos'] = 0\n",
    "    if 'TimeOffsetNanos' in measurements.columns:\n",
    "        measurements['TimeOffsetNanos'] = pd.to_numeric(measurements['TimeOffsetNanos'])\n",
    "    else:\n",
    "        measurements['TimeOffsetNanos'] = 0\n",
    "    \n",
    "    measurements['GpsTimeNanos'] = measurements['TimeNanos'] - (measurements['FullBiasNanos'] - measurements['BiasNanos'])\n",
    "    gpsepoch = datetime(1980, 1, 6, 0, 0, 0)\n",
    "    measurements['UnixTime'] = pd.to_datetime(measurements['GpsTimeNanos'], utc=True, origin=gpsepoch)\n",
    "    measurements['UnixTime'] = measurements['UnixTime']\n",
    "    \n",
    "    # Split data into measurement epochs\n",
    "    measurements['Epoch'] = 0\n",
    "    measurements.loc[measurements['UnixTime'] - measurements['UnixTime'].shift() > timedelta(milliseconds=200), 'Epoch'] = 1\n",
    "    measurements['Epoch'] = measurements['Epoch'].cumsum()\n",
    "    \n",
    "    WEEKSEC = 604800\n",
    "    LIGHTSPEED = 2.99792458e8\n",
    "    \n",
    "    measurements['tRxGnssNanos'] = measurements['TimeNanos'] + measurements['TimeOffsetNanos'] - (measurements['FullBiasNanos'].iloc[0] + measurements['BiasNanos'].iloc[0])\n",
    "    measurements['GpsWeekNumber'] = np.floor(1e-9 * measurements['tRxGnssNanos'] / WEEKSEC)\n",
    "    measurements['tRxSeconds'] = 1e-9 * measurements['tRxGnssNanos'] - WEEKSEC * measurements['GpsWeekNumber']\n",
    "    measurements['tTxSeconds'] = 1e-9 * (measurements['ReceivedSvTimeNanos'] + measurements['TimeOffsetNanos'])\n",
    "    measurements['prSeconds'] = measurements['tRxSeconds'] - measurements['tTxSeconds']\n",
    "    measurements['PrM'] = LIGHTSPEED * measurements['prSeconds']\n",
    "    measurements['PrSigmaM'] = LIGHTSPEED * 1e-9 * measurements['ReceivedSvTimeUncertaintyNanos']\n",
    "    \n",
    "    return measurements\n",
    "\n",
    "#positioing algorithm (3)\n",
    "def calculate_satellite_position(ephemeris, transmit_time):\n",
    "    mu = 3.986005e14\n",
    "    OmegaDot_e = 7.2921151467e-5\n",
    "    F = -4.442807633e-10\n",
    "    sv_position = pd.DataFrame()\n",
    "    sv_position['sv']= ephemeris.index\n",
    "    sv_position.set_index('sv', inplace=True)\n",
    "    sv_position['t_k'] = transmit_time - ephemeris['t_oe']\n",
    "    A = ephemeris['sqrtA'].pow(2)\n",
    "    n_0 = np.sqrt(mu / A.pow(3))\n",
    "    n = n_0 + ephemeris['deltaN']\n",
    "    M_k = ephemeris['M_0'] + n * sv_position['t_k']\n",
    "    E_k = M_k\n",
    "    err = pd.Series(data=[1]*len(sv_position.index))\n",
    "    i = 0\n",
    "    while err.abs().min() > 1e-8 and i < 10:\n",
    "        new_vals = M_k + ephemeris['e']*np.sin(E_k)\n",
    "        err = new_vals - E_k\n",
    "        E_k = new_vals\n",
    "        i += 1\n",
    "        \n",
    "    sinE_k = np.sin(E_k)\n",
    "    cosE_k = np.cos(E_k)\n",
    "    delT_r = F * ephemeris['e'].pow(ephemeris['sqrtA']) * sinE_k\n",
    "    delT_oc = transmit_time - ephemeris['t_oc']\n",
    "    sv_position['delT_sv'] = ephemeris['SVclockBias'] + ephemeris['SVclockDrift'] * delT_oc + ephemeris['SVclockDriftRate'] * delT_oc.pow(2)\n",
    "\n",
    "    v_k = np.arctan2(np.sqrt(1-ephemeris['e'].pow(2))*sinE_k,(cosE_k - ephemeris['e']))\n",
    "\n",
    "    Phi_k = v_k + ephemeris['omega']\n",
    "\n",
    "    sin2Phi_k = np.sin(2*Phi_k)\n",
    "    cos2Phi_k = np.cos(2*Phi_k)\n",
    "\n",
    "    du_k = ephemeris['C_us']*sin2Phi_k + ephemeris['C_uc']*cos2Phi_k\n",
    "    dr_k = ephemeris['C_rs']*sin2Phi_k + ephemeris['C_rc']*cos2Phi_k\n",
    "    di_k = ephemeris['C_is']*sin2Phi_k + ephemeris['C_ic']*cos2Phi_k\n",
    "\n",
    "    u_k = Phi_k + du_k\n",
    "\n",
    "    r_k = A*(1 - ephemeris['e']*np.cos(E_k)) + dr_k\n",
    "\n",
    "    i_k = ephemeris['i_0'] + di_k + ephemeris['IDOT']*sv_position['t_k']\n",
    "\n",
    "    x_k_prime = r_k*np.cos(u_k)\n",
    "    y_k_prime = r_k*np.sin(u_k)\n",
    "\n",
    "    Omega_k = ephemeris['Omega_0'] + (ephemeris['OmegaDot'] - OmegaDot_e)*sv_position['t_k'] - OmegaDot_e*ephemeris['t_oe']\n",
    "\n",
    "    sv_position['x_k'] = x_k_prime*np.cos(Omega_k) - y_k_prime*np.cos(i_k)*np.sin(Omega_k)\n",
    "    sv_position['y_k'] = x_k_prime*np.sin(Omega_k) + y_k_prime*np.cos(i_k)*np.cos(Omega_k)\n",
    "    sv_position['z_k'] = y_k_prime*np.sin(i_k)\n",
    "    return sv_position\n",
    "\n",
    "def least_squares(xs, measured_pseudorange, x0, b0):\n",
    "    dx = 100*np.ones(3)\n",
    "    b = b0\n",
    "    G = np.ones((measured_pseudorange.size, 4))\n",
    "    iterations = 0\n",
    "    while np.linalg.norm(dx) > 1e-3:\n",
    "        r = np.linalg.norm(xs - x0, axis=1)\n",
    "        phat = r + b\n",
    "        deltaP = measured_pseudorange - phat\n",
    "        G[:, 0:3] = -(xs - x0) / r[:, None]\n",
    "        sol = np.linalg.inv(G.T @ G) @ G.T @ deltaP\n",
    "        dx = sol[0:3]\n",
    "        db = sol[3]\n",
    "        x0 = x0 + dx\n",
    "        b = b + db\n",
    "        iterations += 1\n",
    "    norm_dp = np.linalg.norm(deltaP)\n",
    "    return x0, b, norm_dp\n",
    "\n",
    "#combining it all together (5)\n",
    "def save_to_csv_and_kml(measurements, ephemeris_manager, csv_filename, kml_filename):\n",
    "    results = []\n",
    "    kml = simplekml.Kml()\n",
    "    \n",
    "    epoch = 0\n",
    "    while epoch <= measurements['Epoch'].max():\n",
    "        num_sats = 0\n",
    "        while num_sats < 5 and epoch <= measurements['Epoch'].max():\n",
    "            one_epoch = measurements.loc[(measurements['Epoch'] == epoch) & (measurements['prSeconds'] < 0.1)].drop_duplicates(subset='SvName')\n",
    "            if one_epoch.empty:\n",
    "                epoch += 1\n",
    "                continue\n",
    "            timestamp = one_epoch.iloc[0]['UnixTime'].to_pydatetime(warn=False)\n",
    "            one_epoch.set_index('SvName', inplace=True)\n",
    "            num_sats = len(one_epoch.index)\n",
    "            if num_sats < 5:\n",
    "                epoch += 1\n",
    "\n",
    "        if epoch > measurements['Epoch'].max():\n",
    "            break\n",
    "\n",
    "        sats = one_epoch.index.unique().tolist()\n",
    "        ephemeris = ephemeris_manager.get_ephemeris(timestamp, sats)\n",
    "        sv_position = calculate_satellite_position(ephemeris, one_epoch['tTxSeconds'])\n",
    "        \n",
    "        # Add SvName back as a column\n",
    "        sv_position['SvName'] = sv_position.index\n",
    "\n",
    "        # Reset the index to join properly\n",
    "        one_epoch = one_epoch.reset_index()\n",
    "        sv_position = sv_position.reset_index()\n",
    "\n",
    "        result = pd.merge(one_epoch, sv_position, on='SvName')\n",
    "        \n",
    "        # Extract coordinates\n",
    "        weights = result['Cn0DbHz'].to_numpy()  # Using CN0 as weights, adjust as needed\n",
    "        x0 = np.array([0, 0, 0])\n",
    "        b0 = 0\n",
    "        xs = result[['x_k', 'y_k', 'z_k']].to_numpy()\n",
    "        pr = result['PrM'] + LIGHTSPEED * result['delT_sv']\n",
    "        pr = pr.to_numpy()\n",
    "        \n",
    "        receiver_position, receiver_clock_bias, rms_error = least_squares(xs, pr, x0, b0)\n",
    "        x, y, z = receiver_position[0], receiver_position[1], receiver_position[2] #ECEF TO LLA (4)\n",
    "        lat, lon, alt = navpy.ecef2lla([x,y,z])\n",
    "        \n",
    "        result['Pos.X'] = receiver_position[0]\n",
    "        result['Pos.Y'] = receiver_position[1]\n",
    "        result['Pos.Z'] = receiver_position[2]\n",
    "        result['Lat'] = lat\n",
    "        result['Lon'] = lon\n",
    "        result['Alt'] = alt\n",
    "        \n",
    "        results.append(result)\n",
    "\n",
    "        # Add to KML\n",
    "        pnt = kml.newpoint(name=str(timestamp), coords=[(lon, lat, alt)])\n",
    "        pnt.timestamp.when = timestamp.isoformat()\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "    results_df = pd.concat(results)\n",
    "    results_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # Save KML file\n",
    "    kml.save(kml_filename)\n",
    "\n",
    "# List of GNSS log files\n",
    "log_files = ['gnss_log_2024_04_13_19_53_33.txt','gnss_log_2024_04_13_19_52_00.txt','gnss_log_2024_04_13_19_51_17.txt']    \n",
    "\n",
    "# Main script\n",
    "combined_data = pd.DataFrame()\n",
    "# Parse the log file and combine data\n",
    "for log_file in log_files:\n",
    "    measurements = parse_gnss_log(log_file)\n",
    "    manager = EphemerisManager()\n",
    "    name = str(log_file)\n",
    "    name = name[ :-3]\n",
    "    name_kml=name+\"kml\"\n",
    "    name_csv=name+\"csv\"\n",
    "    save_to_csv_and_kml(measurements, manager,name_csv,name_kml)\n",
    "print(\"End of Script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d70b17",
   "metadata": {},
   "source": [
    "# only part A code (as you request to a attach it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d447630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Part A only\n"
     ]
    }
   ],
   "source": [
    "def parse_gnss_log(filepath):\n",
    "    with open(filepath) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if row[0][0] == '#':\n",
    "                if 'Fix' in row[0]:\n",
    "                    android_fixes = [row[1:]]\n",
    "                elif 'Raw' in row[0]:\n",
    "                    measurements = [row[1:]]\n",
    "            else:\n",
    "                if row[0] == 'Fix':\n",
    "                    android_fixes.append(row[1:])\n",
    "                elif row[0] == 'Raw':\n",
    "                    measurements.append(row[1:])\n",
    "\n",
    "    android_fixes = pd.DataFrame(android_fixes[1:], columns=android_fixes[0])\n",
    "    measurements = pd.DataFrame(measurements[1:], columns=measurements[0])\n",
    "    \n",
    "    # Format satellite IDs\n",
    "    measurements.loc[measurements['Svid'].str.len() == 1, 'Svid'] = '0' + measurements['Svid']\n",
    "    measurements.loc[measurements['ConstellationType'] == '1', 'Constellation'] = 'G'\n",
    "    measurements.loc[measurements['ConstellationType'] == '3', 'Constellation'] = 'R'\n",
    "    measurements['SvName'] = measurements['Constellation'] + measurements['Svid']\n",
    "    \n",
    "    # Remove all non-GPS measurements\n",
    "    measurements = measurements.loc[measurements['Constellation'] == 'G']\n",
    "    \n",
    "    # Convert columns to numeric representation\n",
    "    measurements['Cn0DbHz'] = pd.to_numeric(measurements['Cn0DbHz'])\n",
    "    measurements['TimeNanos'] = pd.to_numeric(measurements['TimeNanos'])\n",
    "    measurements['FullBiasNanos'] = pd.to_numeric(measurements['FullBiasNanos'])\n",
    "    measurements['ReceivedSvTimeNanos'] = pd.to_numeric(measurements['ReceivedSvTimeNanos'])\n",
    "    measurements['PseudorangeRateMetersPerSecond'] = pd.to_numeric(measurements['PseudorangeRateMetersPerSecond'])\n",
    "    measurements['ReceivedSvTimeUncertaintyNanos'] = pd.to_numeric(measurements['ReceivedSvTimeUncertaintyNanos'])\n",
    "    \n",
    "    if 'BiasNanos' in measurements.columns:\n",
    "        measurements['BiasNanos'] = pd.to_numeric(measurements['BiasNanos'])\n",
    "    else:\n",
    "        measurements['BiasNanos'] = 0\n",
    "    if 'TimeOffsetNanos' in measurements.columns:\n",
    "        measurements['TimeOffsetNanos'] = pd.to_numeric(measurements['TimeOffsetNanos'])\n",
    "    else:\n",
    "        measurements['TimeOffsetNanos'] = 0\n",
    "    \n",
    "    measurements['GpsTimeNanos'] = measurements['TimeNanos'] - (measurements['FullBiasNanos'] - measurements['BiasNanos'])\n",
    "    gpsepoch = datetime(1980, 1, 6, 0, 0, 0)\n",
    "    measurements['UnixTime'] = pd.to_datetime(measurements['GpsTimeNanos'], utc=True, origin=gpsepoch)\n",
    "    measurements['UnixTime'] = measurements['UnixTime']\n",
    "    \n",
    "    # Split data into measurement epochs\n",
    "    measurements['Epoch'] = 0\n",
    "    measurements.loc[measurements['UnixTime'] - measurements['UnixTime'].shift() > timedelta(milliseconds=200), 'Epoch'] = 1\n",
    "    measurements['Epoch'] = measurements['Epoch'].cumsum()\n",
    "    \n",
    "    WEEKSEC = 604800\n",
    "    LIGHTSPEED = 2.99792458e8\n",
    "    \n",
    "    measurements['tRxGnssNanos'] = measurements['TimeNanos'] + measurements['TimeOffsetNanos'] - (measurements['FullBiasNanos'].iloc[0] + measurements['BiasNanos'].iloc[0])\n",
    "    measurements['GpsWeekNumber'] = np.floor(1e-9 * measurements['tRxGnssNanos'] / WEEKSEC)\n",
    "    measurements['tRxSeconds'] = 1e-9*measurements['tRxGnssNanos'] - WEEKSEC * measurements['GpsWeekNumber']\n",
    "    measurements['tTxSeconds'] = 1e-9*(measurements['ReceivedSvTimeNanos'] + measurements['TimeOffsetNanos'])\n",
    "    measurements['prSeconds'] = measurements['tRxSeconds'] - measurements['tTxSeconds']\n",
    "    measurements['PrM'] = LIGHTSPEED * measurements['prSeconds']\n",
    "    measurements['PrSigmaM'] = LIGHTSPEED * 1e-9 * measurements['ReceivedSvTimeUncertaintyNanos']\n",
    "    \n",
    "    return measurements\n",
    "\n",
    "\n",
    "def save_to_csv(measurements, ephemeris, filename):\n",
    "    epoch = 0\n",
    "    num_sats = 0\n",
    "    while num_sats < 5:\n",
    "        one_epoch = measurements.loc[(measurements['Epoch'] == epoch) & (measurements['prSeconds'] < 0.1)].drop_duplicates(subset='SvName')\n",
    "        timestamp = one_epoch.iloc[0]['UnixTime'].to_pydatetime(warn=False)\n",
    "        one_epoch.set_index('SvName', inplace=True)\n",
    "        num_sats = len(one_epoch.index)\n",
    "        epoch += 1\n",
    "\n",
    "    sats = one_epoch.index.unique().tolist()\n",
    "    ephemeris = manager.get_ephemeris(timestamp, sats)\n",
    "    sv_position = calculate_satellite_position(ephemeris, one_epoch['tTxSeconds'])\n",
    "    #result = one_epoch.join(sv_position)\n",
    "    \n",
    "    sv_position['SvName'] = sv_position.index\n",
    "    one_epoch = one_epoch.reset_index()\n",
    "    sv_position = sv_position.reset_index()\n",
    "    result = pd.merge(one_epoch, sv_position, on='SvName')\n",
    "    \n",
    "    result = result[['UnixTime', 'SvName', 'x_k', 'y_k', 'z_k', 'PrM', 'Cn0DbHz', 'PseudorangeRateMetersPerSecond']]\n",
    "    result.to_csv(filename, index=False, header=['GPS time', 'SatPRN', 'Sat.X', 'Sat.Y', 'Sat.Z', 'Pseudo-Range', 'CN0', 'Doppler'])\n",
    "\n",
    "# List of GNSS log files\n",
    "log_files = ['gnss_log_2024_04_13_19_53_33.txt','gnss_log_2024_04_13_19_52_00.txt','gnss_log_2024_04_13_19_51_17.txt'] \n",
    "\n",
    "# Main\n",
    "for log_file in log_files:\n",
    "    measurements = parse_gnss_log(log_file)\n",
    "    manager = EphemerisManager()\n",
    "    name = str(log_file)  \n",
    "    name = name[ :-4]\n",
    "    name_csv=name+\"_PartA.csv\"\n",
    "    save_to_csv(measurements, manager, name_csv)\n",
    "    \n",
    "print(\"End of Part A only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f7f179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
